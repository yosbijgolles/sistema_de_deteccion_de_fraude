{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b8f923ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import seaborn as sns\n",
    "import pandas as pd  \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69436274",
   "metadata": {},
   "source": [
    "TRANSFORMAR DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e8d9af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=arff.loadarff(\"../data/credit_fraud.arff\")\n",
    "df=pd.DataFrame(data[0])\n",
    "df = df.map(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "df[\"status\"]=df[\"class\"]\n",
    "del df[\"class\"]\n",
    "df['current_balance'] = np.log1p(df['current_balance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035adb04",
   "metadata": {},
   "source": [
    "SELECCIONAR MEJORES FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "70b784b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat=['over_draft','credit_history', 'purpose',\n",
    "           'Average_Credit_Balance', 'employment',\n",
    "           'personal_status',\n",
    "           'property_magnitude', 'other_payment_plans', \n",
    "           'housing',\n",
    "           'status'] # objetivo\n",
    "\n",
    "\n",
    "num=['credit_usage','current_balance','location',\n",
    "             'cc_age','existing_credits']\n",
    "\n",
    "\n",
    "df=df[cat+num]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc51393",
   "metadata": {},
   "source": [
    "CONJUNTOS DE ENTRENAMIENTO Y EVALUACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a3bf5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6f5d3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_full, df_test=train_test_split(\n",
    "    df,test_size=0.2,random_state=11,stratify=df['status'])\n",
    "\n",
    "df_train, df_val=train_test_split(\n",
    "    df_train_full,test_size=0.25,random_state=11,stratify=df_train_full['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c261bbb",
   "metadata": {},
   "source": [
    "VERIFICAMOS QUE STRATIFY PRODUCIÓ BLOQUE PORPROCIONANES RESPECTO AL OBJETIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b94b117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "good    0.7\n",
       "bad     0.3\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6bc397e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "good    0.7\n",
       "bad     0.3\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ee66a95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "good    0.7\n",
       "bad     0.3\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_full.status.value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b470e3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "status\n",
       "good    0.7\n",
       "bad     0.3\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.status.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8599f03",
   "metadata": {},
   "source": [
    "SEPARAMOS LA CARACTERISTICAS DEL OBJETIVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de features en df_train: 15\n",
      "Columnas: ['over_draft', 'credit_history', 'purpose', 'Average_Credit_Balance', 'employment', 'personal_status', 'property_magnitude', 'other_payment_plans', 'housing', 'status', 'credit_usage', 'current_balance', 'location', 'cc_age', 'existing_credits']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['over_draft',\n",
       " 'credit_history',\n",
       " 'purpose',\n",
       " 'Average_Credit_Balance',\n",
       " 'employment',\n",
       " 'personal_status',\n",
       " 'property_magnitude',\n",
       " 'other_payment_plans',\n",
       " 'housing',\n",
       " 'credit_usage',\n",
       " 'current_balance',\n",
       " 'location',\n",
       " 'cc_age',\n",
       " 'existing_credits']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OBJETIVO\n",
    "y_train=(df_train.status=='bad').astype(int).values\n",
    "y_val=(df_val.status=='bad').astype(int).values\n",
    "y_train_full=(df_train_full.status=='bad').astype(int).values\n",
    "y_test=(df_test.status=='bad').astype(int).values\n",
    "\n",
    "# CARACTERISTICAS\n",
    "X_train=df_train.drop('status',axis=1)\n",
    "X_val=df_val.drop('status',axis=1)\n",
    "X_train_full=df_train_full.drop('status',axis=1)\n",
    "X_test=df_test.drop('status',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ffff82",
   "metadata": {},
   "source": [
    "VECTORIZAMOS LAS CARACTERISTICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9494adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4855208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train=X_train.to_dict(orient='records')\n",
    "dict_val=X_val.to_dict(orient='records')\n",
    "dict_train_full=X_train_full.to_dict(orient='records')\n",
    "dict_test=X_test.to_dict(orient='records')\n",
    "\n",
    "dv=DictVectorizer(sparse=False)\n",
    "X_train=dv.fit_transform(dict_train)\n",
    "X_val=dv.transform(dict_val)\n",
    "\n",
    "dv_full = DictVectorizer(sparse=False)\n",
    "X_train_full = dv_full.fit_transform(dict_train_full)  \n",
    "X_test = dv_full.transform(dict_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cfb20",
   "metadata": {},
   "source": [
    "PREPARAMOS UN MODELO GRADIENT BOOSTING PARA CLASIFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "87c5625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab831979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Mejores parámetros: {'subsample': 0.7, 'reg_lambda': 2, 'reg_alpha': 0.1, 'n_estimators': 230, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0, 'colsample_bytree': 0.9}\n",
      "Mejor AUC: 0.78056\n"
     ]
    }
   ],
   "source": [
    "# ESTABLECEMOS RANGO DE BUSQUEDA PARA PARAMETROS DEL MODELO\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0.5, 1, 2],\n",
    "    'n_estimators': range(190,250,5)\n",
    "}\n",
    "\n",
    "# ESPECIFICAMOS UN MODELO XGBOOST\n",
    "modelv1 = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=5 #desvalance de costo\n",
    ")\n",
    "\n",
    "# CONFIGURAMOS LA BUSQUEDA\n",
    "search = RandomizedSearchCV(\n",
    "    modelv1,\n",
    "    param_distributions,\n",
    "    n_iter=30,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,  \n",
    "    random_state=21,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# AJUSTAMOS LA BUSQUEDA A LOS DATOS  \n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(f\"Mejores parámetros: {search.best_params_}\")\n",
    "print(f\"Mejor AUC: {search.best_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7b55d",
   "metadata": {},
   "source": [
    "REENTRENAMOS CON TRAIN + VAL PARA MODELO DE PRODUCCION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "58df62ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "aa11cb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC en FullTrain: 0.863\n",
      "AUC en Test: 0.800\n",
      "Gap: 0.0623 <----- Aceptable\n"
     ]
    }
   ],
   "source": [
    "modelv2 = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scale_pos_weight=5, #desvalance de costo,\n",
    "    **search.best_params_\n",
    ")\n",
    "\n",
    "modelv2.fit(X_train_full, y_train_full)\n",
    "\n",
    "\n",
    "y_pred_train_full = modelv2.predict_proba(X_train_full)[:, 1]\n",
    "full_train_auc = roc_auc_score(y_train_full, y_pred_train_full)\n",
    "print(f\"AUC en FullTrain: {full_train_auc:.3f}\")\n",
    "\n",
    "y_pred_test = modelv2.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "print(f\"AUC en Test: {test_auc:.3f}\")\n",
    "\n",
    "gap = full_train_auc - test_auc\n",
    "\n",
    "if gap<=7:\n",
    "    print(f\"Gap: {gap:.4f} <----- Aceptable\")\n",
    "else: \n",
    "    print(f\"Gap: {gap:.4f} <----- Overfitting\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b513b43",
   "metadata": {},
   "source": [
    "REVISAMOS LA METRICAS DE CLAFICACION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.39      0.55       140\n",
      "           1       0.39      0.90      0.54        60\n",
      "\n",
      "    accuracy                           0.55       200\n",
      "   macro avg       0.65      0.65      0.54       200\n",
      "weighted avg       0.75      0.55      0.55       200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "    0   1\n",
      "0  55  85\n",
      "1   6  54\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = (y_pred_test >= 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred_binary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "14eba42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold  precision    recall        f1  cost  tp   fp  fn   tn\n",
      "0       0.100   0.300000  1.000000  0.461538   140  60  140   0    0\n",
      "1       0.125   0.300000  1.000000  0.461538   140  60  140   0    0\n",
      "2       0.150   0.300000  1.000000  0.461538   140  60  140   0    0\n",
      "3       0.175   0.301508  1.000000  0.463320   139  60  139   0    1\n",
      "4       0.200   0.303030  1.000000  0.465116   138  60  138   0    2\n",
      "5       0.225   0.309278  1.000000  0.472441   134  60  134   0    6\n",
      "6       0.250   0.319149  1.000000  0.483871   128  60  128   0   12\n",
      "7       0.275   0.317204  0.983333  0.479675   132  59  127   1   13\n",
      "8       0.300   0.325967  0.983333  0.489627   127  59  122   1   18\n",
      "9       0.325   0.324022  0.966667  0.485356   131  58  121   2   19\n",
      "10      0.350   0.327684  0.966667  0.489451   129  58  119   2   21\n",
      "11      0.375   0.339181  0.966667  0.502165   123  58  113   2   27\n",
      "12      0.400   0.364780  0.966667  0.529680   111  58  101   2   39\n",
      "13      0.425   0.374194  0.966667  0.539535   107  58   97   2   43\n",
      "14      0.450   0.378378  0.933333  0.538462   112  56   92   4   48\n",
      "15      0.475   0.377622  0.900000  0.532020   119  54   89   6   51\n",
      "16      0.500   0.388489  0.900000  0.542714   115  54   85   6   55\n",
      "17      0.525   0.395522  0.883333  0.546392   116  53   81   7   59\n",
      "18      0.550   0.409449  0.866667  0.556150   115  52   75   8   65\n",
      "19      0.575   0.428571  0.850000  0.569832   113  51   68   9   72\n",
      "20      0.600   0.442478  0.833333  0.578035   113  50   63  10   77\n",
      "21      0.625   0.450450  0.833333  0.584795   111  50   61  10   79\n",
      "22      0.650   0.449541  0.816667  0.579882   115  49   60  11   80\n",
      "23      0.675   0.466667  0.816667  0.593939   111  49   56  11   84\n",
      "24      0.700   0.489796  0.800000  0.607595   110  48   50  12   90\n",
      "25      0.725   0.539326  0.800000  0.644295   101  48   41  12   99\n",
      "26      0.750   0.589041  0.716667  0.646617   115  43   30  17  110\n",
      "27      0.775   0.606557  0.616667  0.611570   139  37   24  23  116\n",
      "28      0.800   0.682927  0.466667  0.554455   173  28   13  32  127\n",
      "29      0.825   0.826087  0.316667  0.457831   209  19    4  41  136\n",
      "30      0.850   0.800000  0.133333  0.228571   262   8    2  52  138\n",
      "31      0.875   1.000000  0.016667  0.032787   295   1    0  59  140\n",
      "32      0.900   0.000000  0.000000  0.000000   300   0    0  60  140\n",
      "33      0.925   0.000000  0.000000  0.000000   300   0    0  60  140\n",
      "\n",
      "✓ Mejor threshold: 0.72\n",
      "  Precision: 0.539\n",
      "  Recall: 0.800\n",
      "  Cost: 101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# 1. Obtener predicciones probabilísticas (NO binarias)\n",
    "y_pred_proba = modelv2.predict_proba(X_test)[:, 1]  # Probabilidad de malo\n",
    "\n",
    "# 2. Probar diferentes thresholds\n",
    "thresholds = np.arange(0.1, 0.95, 0.025)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Aplicar threshold\n",
    "    y_pred_threshold = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_threshold).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    # COST MATRIX: FN cuesta 5x, FP cuesta 1x\n",
    "    cost = (fn * 5) + (fp * 1)\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'cost': cost,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn,\n",
    "        'tn': tn\n",
    "    })\n",
    "\n",
    "# 3. Crear DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "print(df_results.to_string())\n",
    "\n",
    "# 4. Encontrar mejor threshold (por cost mínimo)\n",
    "best_idx = df_results['cost'].idxmin()\n",
    "best_threshold = df_results.loc[best_idx, 'threshold']\n",
    "print(f\"\\n✓ Mejor threshold: {best_threshold:.2f}\")\n",
    "print(f\"  Precision: {df_results.loc[best_idx, 'precision']:.3f}\")\n",
    "print(f\"  Recall: {df_results.loc[best_idx, 'recall']:.3f}\")\n",
    "print(f\"  Cost: {df_results.loc[best_idx, 'cost']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fc9712",
   "metadata": {},
   "source": [
    "IMPORTANCIA DE LA FEATURES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "x6my9medui",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          feature  importance\n",
      "29                         over_draft=no checking    0.104563\n",
      "26                            over_draft=0<=X<200    0.065282\n",
      "38                               purpose=business    0.037875\n",
      "23                       other_payment_plans=bank    0.034887\n",
      "7   credit_history=critical/other existing credit    0.034417\n",
      "27                                  over_draft=<0    0.033876\n",
      "8               credit_history=delayed previously    0.030020\n",
      "37                 property_magnitude=real estate    0.027939\n",
      "47                               purpose=used car    0.027303\n",
      "18                               existing_credits    0.027216\n",
      "15                                  employment=<1    0.025643\n",
      "28                               over_draft=>=200    0.025561\n",
      "24                       other_payment_plans=none    0.024884\n",
      "19                               housing=for free    0.024829\n",
      "11                                   credit_usage    0.023623\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importance = modelv2.feature_importances_\n",
    "feature_names = dv_full.get_feature_names_out()\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importance}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(importance_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610e8729",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "credit_fraud_system-EVkaN002",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
