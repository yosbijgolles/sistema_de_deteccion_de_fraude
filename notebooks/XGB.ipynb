{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost - Detección de Fraude\n",
    "## Optimización de hiperparámetros y búsqueda de threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.io import arff\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1000, 15)\n",
      "\n",
      "Distribución del target:\n",
      "status\n",
      "good    0.7\n",
      "bad     0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "data = arff.loadarff(\"../data/credit_fraud.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df = df.map(lambda x: x.decode() if isinstance(x, bytes) else x)\n",
    "df.rename(columns={'class': 'status'}, inplace=True)\n",
    "\n",
    "# Seleccionar features optimizadas del EDA\n",
    "cat_var = ['over_draft','credit_history', 'purpose', 'Average_Credit_Balance', \n",
    "           'employment', 'personal_status', 'property_magnitude', \n",
    "           'other_payment_plans', 'housing', 'status']\n",
    "num_var = ['credit_usage','current_balance','location','cc_age','existing_credits']\n",
    "\n",
    "df = df[cat_var + num_var]\n",
    "\n",
    "# Aplicar transformación log1p a current_balance\n",
    "df['current_balance'] = np.log1p(df['current_balance'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDistribución del target:\")\n",
    "print(df.status.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. División Train / Val / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 600 | Val: 200 | Test: 200\n"
     ]
    }
   ],
   "source": [
    "# Train+Val (80%) / Test (20%)\n",
    "df_train_full, df_test = train_test_split(\n",
    "    df, test_size=0.2, random_state=21, stratify=df['status'])\n",
    "\n",
    "# Train (60%) / Val (20%)\n",
    "df_train, df_val = train_test_split(\n",
    "    df_train_full, test_size=0.25, random_state=21, stratify=df_train_full['status'])\n",
    "\n",
    "print(f\"Train: {len(df_train)} | Val: {len(df_val)} | Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar X e y\n",
    "y_train = (df_train.status == 'bad').astype(int).values\n",
    "y_val = (df_val.status == 'bad').astype(int).values\n",
    "y_train_full = (df_train_full.status == 'bad').astype(int).values\n",
    "y_test = (df_test.status == 'bad').astype(int).values\n",
    "\n",
    "X_train = df_train.drop('status', axis=1).to_dict('records')\n",
    "X_val = df_val.drop('status', axis=1).to_dict('records')\n",
    "X_train_full = df_train_full.drop('status', axis=1).to_dict('records')\n",
    "X_test = df_test.drop('status', axis=1).to_dict('records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Búsqueda de Hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejor AUC en CV: 0.7833\n",
      "\n",
      "Mejores hiperparámetros:\n",
      "  subsample: 0.8\n",
      "  reg_lambda: 1\n",
      "  reg_alpha: 0.1\n",
      "  n_estimators: 240\n",
      "  min_child_weight: 5\n",
      "  max_depth: 6\n",
      "  learning_rate: 0.1\n",
      "  gamma: 0.2\n",
      "  colsample_bytree: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Definir espacio de búsqueda\n",
    "param_distributions = {\n",
    "    'xgbclassifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "    'xgbclassifier__max_depth': [3, 4, 5, 6],\n",
    "    'xgbclassifier__min_child_weight': [1, 3, 5],\n",
    "    'xgbclassifier__subsample': [0.7, 0.8, 0.9],\n",
    "    'xgbclassifier__colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'xgbclassifier__gamma': [0, 0.1, 0.2],\n",
    "    'xgbclassifier__reg_alpha': [0, 0.1, 0.5],\n",
    "    'xgbclassifier__reg_lambda': [0.5, 1, 2],\n",
    "    'xgbclassifier__n_estimators': range(150, 350, 10)\n",
    "}\n",
    "\n",
    "# Pipeline base\n",
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        random_state=21,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=5\n",
    "    )\n",
    ")\n",
    "\n",
    "# RandomizedSearch\n",
    "search = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions,\n",
    "    n_iter=30,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    random_state=21,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nMejor AUC en CV: {search.best_score_:.4f}\")\n",
    "print(f\"\\nMejores hiperparámetros:\")\n",
    "for param, value in search.best_params_.items():\n",
    "    print(f\"  {param.replace('xgbclassifier__', '')}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluación con Train Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC en Train Full (CV): 0.7580 ± 0.0467\n",
      "AUC en Test: 0.7688\n",
      "Gap: 1.08%\n"
     ]
    }
   ],
   "source": [
    "# Obtener mejores parámetros \n",
    "best_params = {k.replace('xgbclassifier__', ''): v for k, v in search.best_params_.items()}\n",
    "\n",
    "# Modelo con mejores parámetros\n",
    "model_full = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        random_state=21,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=5,\n",
    "        **best_params\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cross-validation en train_full\n",
    "cv_scores = cross_val_score(model_full, X_train_full, y_train_full, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"AUC en Train Full (CV): {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Entrenar y evaluar en test\n",
    "model_full.fit(X_train_full, y_train_full)\n",
    "y_pred_test = model_full.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "print(f\"AUC en Test: {test_auc:.4f}\")\n",
    "\n",
    "gap = np.abs(cv_scores.mean() - test_auc)\n",
    "print(f\"Gap: {100*gap:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8,\n",
       " 'reg_lambda': 1,\n",
       " 'reg_alpha': 0.1,\n",
       " 'n_estimators': 240,\n",
       " 'min_child_weight': 5,\n",
       " 'max_depth': 6,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.2,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Búsqueda de Threshold Óptimo (Matriz de Costos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold óptimo: 0.100\n",
      "Costo mínimo: 100\n",
      "Precision: 0.412\n",
      "Recall: 0.933\n",
      "F1: 0.571\n",
      "\n",
      "Top 5 thresholds (menor costo):\n",
      "   threshold   cost  precision    recall        f1\n",
      "0      0.100  100.0   0.411765  0.933333  0.571429\n",
      "2      0.150  101.0   0.460177  0.866667  0.601156\n",
      "4      0.200  101.0   0.476636  0.850000  0.610778\n",
      "3      0.175  103.0   0.467890  0.850000  0.603550\n",
      "1      0.125  106.0   0.427419  0.883333  0.576087\n"
     ]
    }
   ],
   "source": [
    "# Matriz de costos: FN = 5x, FP = 1x\n",
    "COST_FN = 5.0\n",
    "COST_FP = 1.0\n",
    "\n",
    "thresholds = np.arange(0.1, 0.95, 0.025)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_test >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_threshold).ravel()\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    cost = (fn * COST_FN) + (fp * COST_FP)\n",
    "    \n",
    "    results.append({\n",
    "        'threshold': threshold,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'cost': cost,\n",
    "        'tp': tp, 'fp': fp, 'fn': fn, 'tn': tn\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Mejor threshold (mínimo costo)\n",
    "best_idx = df_results['cost'].idxmin()\n",
    "best_threshold = df_results.loc[best_idx, 'threshold']\n",
    "\n",
    "print(f\"Threshold óptimo: {best_threshold:.3f}\")\n",
    "print(f\"Costo mínimo: {df_results.loc[best_idx, 'cost']:.0f}\")\n",
    "print(f\"Precision: {df_results.loc[best_idx, 'precision']:.3f}\")\n",
    "print(f\"Recall: {df_results.loc[best_idx, 'recall']:.3f}\")\n",
    "print(f\"F1: {df_results.loc[best_idx, 'f1']:.3f}\")\n",
    "\n",
    "print(f\"\\nTop 5 thresholds (menor costo):\")\n",
    "print(df_results.nsmallest(5, 'cost')[['threshold', 'cost', 'precision', 'recall', 'f1']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Métricas de Clasificación con Threshold Óptimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.43      0.59       140\n",
      "           1       0.41      0.93      0.57        60\n",
      "\n",
      "    accuracy                           0.58       200\n",
      "   macro avg       0.67      0.68      0.58       200\n",
      "weighted avg       0.78      0.58      0.58       200\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "           Pred Good  Pred Bad\n",
      "True Good         60        80\n",
      "True Bad           4        56\n"
     ]
    }
   ],
   "source": [
    "y_pred_optimal = (y_pred_test >= best_threshold).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred_optimal))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred_optimal), \n",
    "                   columns=['Pred Good', 'Pred Bad'], \n",
    "                   index=['True Good', 'True Bad']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 features más importantes:\n",
      "                                      feature  importance\n",
      "                       over_draft=no checking    0.124716\n",
      "                Average_Credit_Balance=>=1000    0.038296\n",
      "                             over_draft=>=200    0.036034\n",
      "credit_history=critical/other existing credit    0.034637\n",
      "                             purpose=used car    0.032839\n",
      "                     other_payment_plans=none    0.029873\n",
      "               property_magnitude=real estate    0.028387\n",
      "                            purpose=education    0.027913\n",
      "                                employment=<1    0.027453\n",
      "                            employment=4<=X<7    0.026206\n",
      "           personal_status=female div/dep/mar    0.023389\n",
      "         property_magnitude=no known property    0.023092\n",
      "                  Average_Credit_Balance=<100    0.022553\n",
      "            credit_history=delayed previously    0.022141\n",
      "                             purpose=radio/tv    0.021939\n"
     ]
    }
   ],
   "source": [
    "# Extraer modelo y vectorizer del pipeline\n",
    "xgb_model = model_full.named_steps['xgbclassifier']\n",
    "vectorizer = model_full.named_steps['dictvectorizer']\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': vectorizer.get_feature_names_out(),\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 15 features más importantes:\")\n",
    "print(importance_df.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modelo Final para Producción\n",
    "Entrenar con todos los datos (train + test) usando mejores parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC final (todos los datos, CV): 0.7673 ± 0.0183\n",
      "\n",
      "Modelo final entrenado con todos los datos\n"
     ]
    }
   ],
   "source": [
    "# Preparar todos los datos\n",
    "y_all = (df.status == 'bad').astype(int).values\n",
    "X_all = df.drop('status', axis=1).to_dict('records')\n",
    "\n",
    "# Pipeline final\n",
    "pipeline_final = make_pipeline(\n",
    "    DictVectorizer(),\n",
    "    XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='auc',\n",
    "        random_state=21,\n",
    "        n_jobs=-1,\n",
    "        scale_pos_weight=5,\n",
    "        **best_params\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cross-validation final\n",
    "cv_scores_final = cross_val_score(pipeline_final, X_all, y_all, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "print(f\"AUC final (todos los datos, CV): {cv_scores_final.mean():.4f} ± {cv_scores_final.std():.4f}\")\n",
    "\n",
    "# Entrenar modelo final\n",
    "pipeline_final.fit(X_all, y_all)\n",
    "print(\"\\nModelo final entrenado con todos los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Guardar Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('../models/model_XGB_v0.bin', 'wb') as f_out:\n",
    "#    pickle.dump(pipeline_final, f_out)\n",
    "\n",
    "#print(\"Modelo guardado en: ../models/model_XGB_v0.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Test de Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bad_probability': 0.486, 'fraude': True}\n"
     ]
    }
   ],
   "source": [
    "# Cargar modelo\n",
    "with open('../models/model_XGB.bin', 'rb') as f_in:\n",
    "    loaded_pipeline = pickle.load(f_in)\n",
    "\n",
    "# Cliente de prueba (valores originales, sin transformación)\n",
    "client = {\n",
    "    'over_draft': '0<=X<200',\n",
    "    'credit_history': 'critical/other existing credit',\n",
    "    'purpose': 'education',\n",
    "    'Average_Credit_Balance': 'no known savings',\n",
    "    'employment': '1<=X<4',\n",
    "    'personal_status': 'female div/dep/mar',\n",
    "    'property_magnitude': 'car',\n",
    "    'other_payment_plans': 'none',\n",
    "    'housing': 'own',\n",
    "    'credit_usage': 24.0,\n",
    "    'current_balance': 1926.0,  # Valor original (se aplicará log1p en producción)\n",
    "    'location': 3.0,\n",
    "    'cc_age': 33.0,\n",
    "    'existing_credits': 2.0\n",
    "}\n",
    "\n",
    "# Aplicar transformación necesaria\n",
    "client['current_balance'] = np.log1p(client['current_balance'])\n",
    "\n",
    "# Predicción\n",
    "y_pred = loaded_pipeline.predict_proba([client])[0, 1]\n",
    "fraude = y_pred >= best_threshold\n",
    "\n",
    "result = {\n",
    "    'bad_probability': float(f'{y_pred:.3f}'),\n",
    "    'fraude': bool(fraude),\n",
    "    #'threshold_usado': best_threshold\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistema_de_deteccion_de_fraude-gz0kFX-4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
